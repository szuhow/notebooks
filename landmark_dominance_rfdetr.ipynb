{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Podejście topologiczne: RF-DETR na punktach orientacyjnych → dominacja\n",
        "\n",
        "**Cel:** Zamiast klasyfikatora right/left (ResNet) lub głosowania po segmentach — model wykrywa **landmarky anatomiczne**, a dominacja jest wyznaczana **post-processingiem** (odległość Crux vs dystalne końce RCA/LCx).\n",
        "\n",
        "**Zalety:**\n",
        "- RT-DETR (self-attention) widzi relacje globalne (ujście RCA ↔ crux cordis).\n",
        "- Wynik interpretowalny: widać, gdzie model umieścił Crux i końce naczyń.\n",
        "- Mniej zależny od pojedynczego segmentu (np. 4/PDA), który może być niewidoczny.\n",
        "\n",
        "**Architektura:**\n",
        "1. **Backbone + Transformer (RF-DETR)** — jedna klatka angiografii (np. max opacification).\n",
        "2. **5 klas landmarków:** A=RCA Ostium, B=LCA Ostium, C=Crux Cordis, D=Distal RCA, E=Distal LCx.\n",
        "3. **Logika dominacji:** odległość euklidesowa (lub IoU) Crux ↔ D vs Crux ↔ E → Right vs Left dominance."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Definicja 5 klas landmarków i mapowanie z segmentów ARCADE\n",
        "\n",
        "| Klasa | Nazwa           | Źródło w ARCADE (segmenty) | Opis |\n",
        "|-------|-----------------|----------------------------|------|\n",
        "| 1     | RCA Ostium      | segment 1 (RCA prox)       | Ujście prawej tętnicy wieńcowej |\n",
        "| 2     | LCA Ostium      | segment 5 (LM)             | Ujście lewej tętnicy (LM) |\n",
        "| 3     | Crux Cordis     | segment 4 (PDA) / koniec RCA | Skrzyżowanie bruzd (tylna ściana) |\n",
        "| 4     | Distal RCA      | segment 3 (RCA dist) lub 4 (PDA) | Dystalny koniec RCA |\n",
        "| 5     | Distal LCx      | segment 15 (LCx dist) lub 16 (PLB) | Dystalny koniec gałęzi okalającej |\n",
        "\n",
        "**Uwaga:** Landmarky można anotować ręcznie (punkt lub mały bbox) albo **wyprowadzić z masek 25-class** (centroid / punkt dystalny maski)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Stałe dla pipeline'u landmarków (num_classes=5)\n",
        "LANDMARK_CLASSES = [\n",
        "    \"rca_ostium\",   # 1\n",
        "    \"lca_ostium\",   # 2\n",
        "    \"crux_cordis\",  # 3\n",
        "    \"distal_rca\",   # 4\n",
        "    \"distal_lcx\",   # 5\n",
        "]\n",
        "LANDMARK_ID_CRUX = 3\n",
        "LANDMARK_ID_DISTAL_RCA = 4\n",
        "LANDMARK_ID_DISTAL_LCX = 5\n",
        "\n",
        "# Mapowanie: segment ARCADE (class_id 1–25) → landmark (1–5). Jeden segment → jeden landmark (priorytet).\n",
        "SEGMENT_TO_LANDMARK = {\n",
        "    1: 1,   # RCA prox → rca_ostium\n",
        "    5: 2,   # LM → lca_ostium\n",
        "    4: 3,   # PDA → crux_cordis\n",
        "    3: 4,   # RCA dist → distal_rca\n",
        "    19: 5,  # LCx dist → distal_lcx\n",
        "    20: 5,  # PLB → distal_lcx\n",
        "}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Generowanie datasetu COCO dla 5 landmarków z istniejącego datasetu 25-class\n",
        "\n",
        "Dla każdego obrazu z `_annotations.coco.json` (25 segmentów):\n",
        "- Dla każdej kategorii segmentu mapowanej do landmarku: oblicz bbox (lub centroid) maski → zapisz jako ann do kategorii landmarku 1–5.\n",
        "- Jedna maska segmentu może dać jeden bbox/point na jeden landmark; przy konfliktach (np. segment 4 → crux i distal_rca) można duplikować lub wybrać jedną regułę (np. PDA tylko crux)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "import json\n",
        "import os\n",
        "from pathlib import Path\n",
        "from pycocotools import mask as mask_utils\n",
        "import numpy as np\n",
        "\n",
        "def segments_coco_to_landmark_coco(\n",
        "    coco_path: str,\n",
        "    images_dir: str,\n",
        "    output_dir: str,\n",
        "    segment_to_landmark: dict,\n",
        "    min_mask_area: int = 100,\n",
        ") -> str:\n",
        "    \"\"\"\n",
        "    Czyta COCO z 25 segmentami, dla każdej ann mapuje segment -> landmark,\n",
        "    buduje bbox z maski (lub RLE) i zapisuje nowy _annotations.coco.json z 5 kategoriami.\n",
        "    \"\"\"\n",
        "    with open(coco_path) as f:\n",
        "        coco = json.load(f)\n",
        "    os.makedirs(output_dir, exist_ok=True)\n",
        "    out_images_dir = os.path.join(output_dir, \"images\")\n",
        "    os.makedirs(out_images_dir, exist_ok=True)\n",
        "\n",
        "    cat_id_old_to_new = {}\n",
        "    new_cats = []\n",
        "    for i, name in enumerate(LANDMARK_CLASSES, start=1):\n",
        "        new_cats.append({\"id\": i, \"name\": name, \"supercategory\": \"landmark\"})\n",
        "        cat_id_old_to_new[i] = i\n",
        "    new_anns = []\n",
        "    ann_id = 1\n",
        "    for ann in coco[\"annotations\"]:\n",
        "        cat_old = ann[\"category_id\"]\n",
        "        if cat_old not in segment_to_landmark:\n",
        "            continue\n",
        "        landmark_id = segment_to_landmark[cat_old]\n",
        "        if \"segmentation\" in ann and ann[\"segmentation\"]:\n",
        "            seg = ann[\"segmentation\"]\n",
        "            if isinstance(seg, list) and len(seg):\n",
        "                poly = np.array(seg[0]).reshape(-1, 2)\n",
        "                if poly.size < 6:\n",
        "                    continue\n",
        "                x, y = poly[:, 0], poly[:, 1]\n",
        "                x_min, x_max = float(x.min()), float(x.max())\n",
        "                y_min, y_max = float(y.min()), float(y.max())\n",
        "            elif isinstance(seg, dict) and \"counts\" in seg:\n",
        "                try:\n",
        "                    m = mask_utils.decode(seg)\n",
        "                    if m.size and m.ndim >= 2:\n",
        "                        ys, xs = np.where(m > 0)\n",
        "                        if xs.size:\n",
        "                            x_min, x_max = float(xs.min()), float(xs.max())\n",
        "                            y_min, y_max = float(ys.min()), float(ys.max())\n",
        "                        else:\n",
        "                            continue\n",
        "                    else:\n",
        "                        continue\n",
        "                except Exception:\n",
        "                    continue\n",
        "            else:\n",
        "                continue\n",
        "        elif \"bbox\" in ann:\n",
        "            x_min = ann[\"bbox\"][0]\n",
        "            y_min = ann[\"bbox\"][1]\n",
        "            x_max = x_min + ann[\"bbox\"][2]\n",
        "            y_max = y_min + ann[\"bbox\"][3]\n",
        "        else:\n",
        "            continue\n",
        "        w, h = x_max - x_min, y_max - y_min\n",
        "        if w * h < min_mask_area:\n",
        "            continue\n",
        "        seg_poly = [[x_min, y_min, x_min + w, y_min, x_min + w, y_min + h, x_min, y_min + h]]\n",
        "        new_anns.append({\n",
        "            \"id\": ann_id,\n",
        "            \"image_id\": ann[\"image_id\"],\n",
        "            \"category_id\": landmark_id,\n",
        "            \"bbox\": [x_min, y_min, w, h],\n",
        "            \"area\": w * h,\n",
        "            \"iscrowd\": 0,\n",
        "            \"segmentation\": seg_poly,\n",
        "        })\n",
        "        ann_id += 1\n",
        "    image_ids_with_anns = {a[\"image_id\"] for a in new_anns}\n",
        "    new_images = [\n",
        "        {\"id\": img[\"id\"], \"file_name\": img[\"file_name\"], \"width\": img[\"width\"], \"height\": img[\"height\"]}\n",
        "        for img in coco[\"images\"] if img[\"id\"] in image_ids_with_anns\n",
        "    ]\n",
        "    out_coco = {\"images\": new_images, \"annotations\": new_anns, \"categories\": new_cats}\n",
        "    out_path = os.path.join(output_dir, \"_annotations.coco.json\")\n",
        "    with open(out_path, \"w\") as f:\n",
        "        json.dump(out_coco, f, indent=2)\n",
        "    return out_path"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Patched: arcade_landmark_5class/train/_annotations.coco.json\n",
            "Patched: arcade_landmark_5class/valid/_annotations.coco.json\n",
            "Patched: arcade_landmark_5class/test/_annotations.coco.json\n"
          ]
        }
      ],
      "source": [
        "# Jednorazowa poprawka: dodaj supercategory do już wygenerowanego _annotations.coco.json\n",
        "# (rfdetr wymaga tego pola w categories). Uruchom raz, potem trening zadziała.\n",
        "def patch_coco_supercategory(dataset_dir: str = \"arcade_landmark_5class\", supercat: str = \"landmark\"):\n",
        "    for split in [\"train\", \"valid\", \"test\"]:\n",
        "        path = os.path.join(dataset_dir, split, \"_annotations.coco.json\")\n",
        "        if not os.path.exists(path):\n",
        "            continue\n",
        "        with open(path) as f:\n",
        "            data = json.load(f)\n",
        "        for c in data.get(\"categories\", []):\n",
        "            if \"supercategory\" not in c:\n",
        "                c[\"supercategory\"] = supercat\n",
        "        with open(path, \"w\") as f:\n",
        "            json.dump(data, f, indent=2)\n",
        "        print(f\"Patched: {path}\")\n",
        "patch_coco_supercategory()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Done: train\n",
            "Done: valid\n",
            "Done: test\n"
          ]
        }
      ],
      "source": [
        "# Przykład: konwersja train/valid z datasetu 25-class na dataset 5 landmarków\n",
        "# ARCADE_COCO = \"arcade_coco_dataset_multiclass_seg\"\n",
        "ARCADE_COCO = \"/Users/rafalszulinski/Desktop/developing/IVES/coronary/rf-detr-seg/notebooks/notebooks/arcade_coco_detection2\"  # COCO multiclass dataset\n",
        "\n",
        "for split in [\"train\", \"valid\", \"test\"]:\n",
        "    coco_path = os.path.join(ARCADE_COCO, split, \"_annotations.coco.json\")\n",
        "    if os.path.exists(coco_path):\n",
        "        segments_coco_to_landmark_coco(\n",
        "            coco_path,\n",
        "            images_dir=os.path.join(ARCADE_COCO, split),\n",
        "            output_dir=os.path.join(\"arcade_landmark_5class\", split),\n",
        "            segment_to_landmark=SEGMENT_TO_LANDMARK,\n",
        "        )\n",
        "        print(f\"Done: {split}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Trening RF-DETR z 5 klasami (landmarky)\n",
        "\n",
        "Model ten sam co w pipeline (RFDETRSegLarge), ale `num_classes=5`. Dataset w formacie COCO z 5 kategoriami (jak wyżej)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[2026-02-16 13:25:34] [INFO] rf-detr - File rf-detr-seg-small.pt already exists with correct MD5 hash.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[2026-02-16 13:25:34] [WARNING] rf-detr - Using a different number of positional encodings than DINOv2, which means we're not loading DINOv2 backbone weights. This is not a problem if finetuning a pretrained RF-DETR model.\n",
            "[2026-02-16 13:25:34] [WARNING] rf-detr - Using patch size 12 instead of 14, which means we're not loading DINOv2 backbone weights. This is not a problem if finetuning a pretrained RF-DETR model.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[2026-02-16 13:25:34] [INFO] rf-detr - Loading pretrain weights\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[2026-02-16 13:25:34] [WARNING] rf-detr - Reinitializing detection head with 90 classes based on pretrained weights, configured for 5.\n",
            "[2026-02-16 13:25:35] [WARNING] rf-detr - Reinitializing your detection head with 6 classes.\n",
            "[2026-02-16 13:25:35] [WARNING] rf-detr - Unable to initialize TensorBoard. Logging is turned off for this session. Run 'pip install tensorboard' to enable logging.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[2026-02-16 13:25:35] [INFO] rf-detr - Not using distributed mode\n",
            "[2026-02-16 13:25:35] [INFO] rf-detr - git:\n",
            "  unknown\n",
            "\n",
            "[2026-02-16 13:25:35] [INFO] rf-detr - Namespace(num_classes=6, grad_accum_steps=4, print_freq=10, amp=True, lr=0.0005, lr_encoder=5e-05, batch_size=2, weight_decay=0.0001, epochs=10, lr_drop=100, clip_max_norm=0.1, lr_vit_layer_decay=0.8, lr_component_decay=0.7, do_benchmark=False, dropout=0, drop_path=0.0, drop_mode='standard', drop_schedule='constant', cutoff_epoch=0, pretrained_encoder=None, pretrain_weights='rf-detr-seg-small.pt', pretrain_exclude_keys=None, pretrain_keys_modify_to_load=None, pretrained_distiller=None, encoder='dinov2_windowed_small', vit_encoder_num_layers=12, window_block_indexes=None, position_embedding='sine', out_feature_indexes=[3, 6, 9, 12], freeze_encoder=False, layer_norm=True, rms_norm=False, backbone_lora=False, force_no_pretrain=False, dec_layers=4, dim_feedforward=2048, hidden_dim=256, sa_nheads=8, ca_nheads=16, num_queries=100, group_detr=13, two_stage=True, projector_scale=['P4'], lite_refpoint_refine=True, num_select=300, dec_n_points=2, decoder_norm='LN', bbox_reparam=True, freeze_batch_norm=False, set_cost_class=2, set_cost_bbox=5, set_cost_giou=2, cls_loss_coef=5.0, bbox_loss_coef=5, giou_loss_coef=2, focal_alpha=0.25, aux_loss=True, sum_group_losses=False, use_varifocal_loss=False, use_position_supervised_loss=False, ia_bce_loss=True, dataset_file='roboflow', coco_path=None, dataset_dir='/Users/rafalszulinski/Desktop/developing/IVES/coronary/rf-detr-seg/notebooks/arcade_landmark_5class', square_resize_div_64=True, output_dir='/Users/rafalszulinski/Desktop/developing/IVES/coronary/rf-detr-seg/notebooks/checkpoints_landmark5', dont_save_weights=False, checkpoint_interval=5, seed=42, resume=None, start_epoch=0, eval=False, use_ema=True, ema_decay=0.993, ema_tau=100, num_workers=2, device='mps', world_size=1, dist_url='env://', sync_bn=True, fp16_eval=False, encoder_only=False, backbone_only=False, resolution=384, use_cls_token=False, multi_scale=True, expanded_scales=True, do_random_resize_via_padding=False, warmup_epochs=3.0, lr_scheduler='cosine', lr_min_factor=0.0, early_stopping=True, early_stopping_patience=12, early_stopping_min_delta=0.001, early_stopping_use_ema=False, gradient_checkpointing=False, patch_size=12, num_windows=2, positional_encoding_size=32, mask_downsample_ratio=4, license='Apache-2.0', tensorboard=True, wandb=False, mlflow=False, clearml=False, project=None, run=None, class_names=['rca_ostium', 'lca_ostium', 'crux_cordis', 'distal_rca', 'distal_lcx'], run_test=True, segmentation_head=True, eval_max_dets=500, mask_point_sample_ratio=16, mask_ce_loss_coef=5.0, mask_dice_loss_coef=5.0, distributed=False)\n",
            "[2026-02-16 13:25:35] [INFO] rf-detr - Number of trainable parameters: 33405277 (33.41 M)\n",
            "[2026-02-16 13:25:35] [INFO] rf-detr - Building Roboflow train dataset with square resize at resolution 384\n",
            "[2026-02-16 13:25:35] [INFO] rf-detr - Using multi-scale training with square resize and scales: [504]\n",
            "loading annotations into memory...\n",
            "Done (t=0.01s)\n",
            "creating index...\n",
            "index created!\n",
            "[2026-02-16 13:25:35] [INFO] rf-detr - Building Roboflow val dataset with square resize at resolution 384\n",
            "[2026-02-16 13:25:35] [INFO] rf-detr - Using multi-scale training with square resize and scales: [504]\n",
            "loading annotations into memory...\n",
            "Done (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "[2026-02-16 13:25:35] [INFO] rf-detr - Building Roboflow test dataset with square resize at resolution 384\n",
            "[2026-02-16 13:25:35] [INFO] rf-detr - Using multi-scale training with square resize and scales: [504]\n",
            "loading annotations into memory...\n",
            "Done (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "[2026-02-16 13:25:35] [INFO] rf-detr - Dataset loaded: 912 training samples, 196 validation samples\n",
            "[2026-02-16 13:25:35] [INFO] rf-detr - Get benchmark\n",
            "[2026-02-16 13:25:35] [INFO] rf-detr - Start training\n",
            "[2026-02-16 13:25:35] [INFO] rf-detr - Training config: grad_accum_steps=4, total_batch_size=8, dataloader_length=114\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "fatal: to nie jest repozytorium gita (ani żaden z katalogów nadrzędnych): .git\n",
            "RuntimeWarning: Setting num_workers to 0 because the script is not wrapped in `if __name__ == '__main__':`. This is required for multiprocessing with the 'spawn' start method.\n",
            "UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
            "UserWarning: CUDA is not available or torch_xla is imported. Disabling autocast.\n",
            "UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at /Users/runner/work/pytorch/pytorch/pytorch/aten/src/ATen/native/TensorShape.cpp:4383.)\n",
            "UserWarning: Using a non-tuple sequence for multidimensional indexing is deprecated and will be changed in pytorch 2.9; use x[tuple(seq)] instead of x[seq]. In pytorch 2.9 this will be interpreted as tensor index, x[torch.tensor(seq)], which will result either in an error or a different result (Triggered internally at /Users/runner/work/pytorch/pytorch/pytorch/torch/csrc/autograd/python_variable_indexing.cpp:353.)\n",
            "UserWarning: Using a non-tuple sequence for multidimensional indexing is deprecated and will be changed in pytorch 2.9; use x[tuple(seq)] instead of x[seq]. In pytorch 2.9 this will be interpreted as tensor index, x[torch.tensor(seq)], which will result either in an error or a different result (Triggered internally at /Users/runner/work/pytorch/pytorch/pytorch/torch/csrc/autograd/python_variable_indexing.cpp:353.)\n",
            "UserWarning: Using a non-tuple sequence for multidimensional indexing is deprecated and will be changed in pytorch 2.9; use x[tuple(seq)] instead of x[seq]. In pytorch 2.9 this will be interpreted as tensor index, x[torch.tensor(seq)], which will result either in an error or a different result (Triggered internally at /Users/runner/work/pytorch/pytorch/pytorch/torch/csrc/autograd/python_variable_indexing.cpp:353.)\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[17]\u001b[39m\u001b[32m, line 8\u001b[39m\n\u001b[32m      6\u001b[39m LANDMARK_DATASET = \u001b[33m\"\u001b[39m\u001b[33marcade_landmark_5class\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m      7\u001b[39m model_landmark = RFDETRSegSmall(num_classes=\u001b[32m5\u001b[39m)\n\u001b[32m----> \u001b[39m\u001b[32m8\u001b[39m \u001b[43mmodel_landmark\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m      9\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdataset_dir\u001b[49m\u001b[43m=\u001b[49m\u001b[43mLANDMARK_DATASET\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     10\u001b[39m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m10\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     11\u001b[39m \u001b[43m    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m2\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     12\u001b[39m \u001b[43m    \u001b[49m\u001b[43mlr\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m5e-4\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     13\u001b[39m \u001b[43m    \u001b[49m\u001b[43mlr_encoder\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m5e-5\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     14\u001b[39m \u001b[43m    \u001b[49m\u001b[43mlr_scheduler\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcosine\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     15\u001b[39m \u001b[43m    \u001b[49m\u001b[43mwarmup_epochs\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m3\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     16\u001b[39m \u001b[43m    \u001b[49m\u001b[43muse_ema\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m     17\u001b[39m \u001b[43m    \u001b[49m\u001b[43mearly_stopping\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m     18\u001b[39m \u001b[43m    \u001b[49m\u001b[43mearly_stopping_patience\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m12\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     19\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcheckpoint_interval\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m5\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     20\u001b[39m \u001b[43m    \u001b[49m\u001b[43moutput_dir\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcheckpoints_landmark5\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     21\u001b[39m \u001b[43m)\u001b[49m\n\u001b[32m     22\u001b[39m model_landmark.optimize_for_inference()\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/developing/IVES/coronary/rf-detr-seg/.venv/lib/python3.13/site-packages/rfdetr/detr.py:103\u001b[39m, in \u001b[36mRFDETR.train\u001b[39m\u001b[34m(self, **kwargs)\u001b[39m\n\u001b[32m     99\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    100\u001b[39m \u001b[33;03mTrain an RF-DETR model.\u001b[39;00m\n\u001b[32m    101\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    102\u001b[39m config = \u001b[38;5;28mself\u001b[39m.get_train_config(**kwargs)\n\u001b[32m--> \u001b[39m\u001b[32m103\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtrain_from_config\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/developing/IVES/coronary/rf-detr-seg/.venv/lib/python3.13/site-packages/rfdetr/detr.py:264\u001b[39m, in \u001b[36mRFDETR.train_from_config\u001b[39m\u001b[34m(self, config, **kwargs)\u001b[39m\n\u001b[32m    255\u001b[39m     early_stopping_callback = EarlyStoppingCallback(\n\u001b[32m    256\u001b[39m         model=\u001b[38;5;28mself\u001b[39m.model,\n\u001b[32m    257\u001b[39m         patience=config.early_stopping_patience,\n\u001b[32m   (...)\u001b[39m\u001b[32m    260\u001b[39m         segmentation_head=config.segmentation_head\n\u001b[32m    261\u001b[39m     )\n\u001b[32m    262\u001b[39m     \u001b[38;5;28mself\u001b[39m.callbacks[\u001b[33m\"\u001b[39m\u001b[33mon_fit_epoch_end\u001b[39m\u001b[33m\"\u001b[39m].append(early_stopping_callback.update)\n\u001b[32m--> \u001b[39m\u001b[32m264\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    265\u001b[39m \u001b[43m    \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mall_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    266\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    267\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/developing/IVES/coronary/rf-detr-seg/.venv/lib/python3.13/site-packages/rfdetr/main.py:360\u001b[39m, in \u001b[36mModel.train\u001b[39m\u001b[34m(self, callbacks, **kwargs)\u001b[39m\n\u001b[32m    358\u001b[39m model.train()\n\u001b[32m    359\u001b[39m criterion.train()\n\u001b[32m--> \u001b[39m\u001b[32m360\u001b[39m train_stats = \u001b[43mtrain_one_epoch\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    361\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlr_scheduler\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata_loader_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepoch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    362\u001b[39m \u001b[43m    \u001b[49m\u001b[43meffective_batch_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m.\u001b[49m\u001b[43mclip_max_norm\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mema_m\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mema_m\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mschedules\u001b[49m\u001b[43m=\u001b[49m\u001b[43mschedules\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    363\u001b[39m \u001b[43m    \u001b[49m\u001b[43mnum_training_steps_per_epoch\u001b[49m\u001b[43m=\u001b[49m\u001b[43mnum_training_steps_per_epoch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    364\u001b[39m \u001b[43m    \u001b[49m\u001b[43mvit_encoder_num_layers\u001b[49m\u001b[43m=\u001b[49m\u001b[43margs\u001b[49m\u001b[43m.\u001b[49m\u001b[43mvit_encoder_num_layers\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m=\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    365\u001b[39m train_epoch_time = time.time() - epoch_start_time\n\u001b[32m    366\u001b[39m train_epoch_time_str = \u001b[38;5;28mstr\u001b[39m(datetime.timedelta(seconds=\u001b[38;5;28mint\u001b[39m(train_epoch_time)))\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/developing/IVES/coronary/rf-detr-seg/.venv/lib/python3.13/site-packages/rfdetr/engine.py:151\u001b[39m, in \u001b[36mtrain_one_epoch\u001b[39m\u001b[34m(model, criterion, lr_scheduler, data_loader, optimizer, device, epoch, batch_size, max_norm, ema_m, schedules, num_training_steps_per_epoch, vit_encoder_num_layers, args, callbacks)\u001b[39m\n\u001b[32m    144\u001b[39m         losses = \u001b[38;5;28msum\u001b[39m(\n\u001b[32m    145\u001b[39m             (\u001b[32m1\u001b[39m / args.grad_accum_steps) * loss_dict[k] * weight_dict[k]\n\u001b[32m    146\u001b[39m             \u001b[38;5;28;01mfor\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m loss_dict.keys()\n\u001b[32m    147\u001b[39m             \u001b[38;5;28;01mif\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m weight_dict\n\u001b[32m    148\u001b[39m         )\n\u001b[32m    149\u001b[39m         \u001b[38;5;28;01mdel\u001b[39;00m outputs\n\u001b[32m--> \u001b[39m\u001b[32m151\u001b[39m     \u001b[43mscaler\u001b[49m\u001b[43m.\u001b[49m\u001b[43mscale\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlosses\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    153\u001b[39m \u001b[38;5;66;03m# reduce losses over all GPUs for logging purposes\u001b[39;00m\n\u001b[32m    154\u001b[39m loss_dict_reduced = utils.reduce_dict(loss_dict)\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/developing/IVES/coronary/rf-detr-seg/.venv/lib/python3.13/site-packages/torch/_tensor.py:631\u001b[39m, in \u001b[36mTensor.backward\u001b[39m\u001b[34m(self, gradient, retain_graph, create_graph, inputs)\u001b[39m\n\u001b[32m    621\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m    622\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[32m    623\u001b[39m         Tensor.backward,\n\u001b[32m    624\u001b[39m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[32m   (...)\u001b[39m\u001b[32m    629\u001b[39m         inputs=inputs,\n\u001b[32m    630\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m631\u001b[39m \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mautograd\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    632\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m=\u001b[49m\u001b[43minputs\u001b[49m\n\u001b[32m    633\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/developing/IVES/coronary/rf-detr-seg/.venv/lib/python3.13/site-packages/torch/autograd/__init__.py:381\u001b[39m, in \u001b[36mbackward\u001b[39m\u001b[34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[39m\n\u001b[32m    376\u001b[39m     retain_graph = create_graph\n\u001b[32m    378\u001b[39m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[32m    379\u001b[39m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[32m    380\u001b[39m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m381\u001b[39m \u001b[43m_engine_run_backward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    382\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    383\u001b[39m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    384\u001b[39m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    385\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    386\u001b[39m \u001b[43m    \u001b[49m\u001b[43minputs_tuple\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    387\u001b[39m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    388\u001b[39m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    389\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/developing/IVES/coronary/rf-detr-seg/.venv/lib/python3.13/site-packages/torch/autograd/graph.py:869\u001b[39m, in \u001b[36m_engine_run_backward\u001b[39m\u001b[34m(t_outputs, *args, **kwargs)\u001b[39m\n\u001b[32m    867\u001b[39m     unregister_hooks = _register_logging_hooks_on_whole_graph(t_outputs)\n\u001b[32m    868\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m869\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mVariable\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_execution_engine\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[32m    870\u001b[39m \u001b[43m        \u001b[49m\u001b[43mt_outputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\n\u001b[32m    871\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[32m    872\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    873\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m attach_logging_hooks:\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/3.13.0rc1/lib/python3.13/warnings.py:425\u001b[39m, in \u001b[36mWarningMessage.__init__\u001b[39m\u001b[34m(self, message, category, filename, lineno, file, line, source)\u001b[39m\n\u001b[32m    420\u001b[39m \u001b[38;5;28;01mclass\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mWarningMessage\u001b[39;00m(\u001b[38;5;28mobject\u001b[39m):\n\u001b[32m    422\u001b[39m     _WARNING_DETAILS = (\u001b[33m\"\u001b[39m\u001b[33mmessage\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mcategory\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mfilename\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mlineno\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mfile\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    423\u001b[39m                         \u001b[33m\"\u001b[39m\u001b[33mline\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33msource\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m425\u001b[39m     \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, message, category, filename, lineno, file=\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m    426\u001b[39m                  line=\u001b[38;5;28;01mNone\u001b[39;00m, source=\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[32m    427\u001b[39m         \u001b[38;5;28mself\u001b[39m.message = message\n\u001b[32m    428\u001b[39m         \u001b[38;5;28mself\u001b[39m.category = category\n",
            "\u001b[31mKeyboardInterrupt\u001b[39m: "
          ]
        }
      ],
      "source": [
        "import logging\n",
        "if not hasattr(logging, \"warn\"):\n",
        "    logging.warn = logging.warning\n",
        "from rfdetr import RFDETRSegSmall\n",
        "\n",
        "LANDMARK_DATASET = \"arcade_landmark_5class\"\n",
        "model_landmark = RFDETRSegSmall(num_classes=5)\n",
        "model_landmark.train(\n",
        "    dataset_dir=LANDMARK_DATASET,\n",
        "    epochs=10,\n",
        "    batch_size=2,\n",
        "    lr=5e-4,\n",
        "    lr_encoder=5e-5,\n",
        "    lr_scheduler=\"cosine\",\n",
        "    warmup_epochs=3,\n",
        "    use_ema=True,\n",
        "    early_stopping=True,\n",
        "    early_stopping_patience=12,\n",
        "    checkpoint_interval=5,\n",
        "    output_dir=\"checkpoints_landmark5\",\n",
        ")\n",
        "model_landmark.optimize_for_inference()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Logika dominacji (post-processing)\n",
        "\n",
        "Po inference RF-DETR zwraca bboxe (lub maski) dla każdego landmarku. Dla dominacji potrzebujemy:\n",
        "- **Crux Cordis** (class_id=3)\n",
        "- **Distal RCA** (4)\n",
        "- **Distal LCx** (5)\n",
        "\n",
        "**Reguła:**\n",
        "- Środek bboxa = reprezentacja punktu landmarku.\n",
        "- `d_crux_rca` = odległość euklidesowa (środek Crux, środek Distal RCA).\n",
        "- `d_crux_lcx` = odległość (Crux, Distal LCx).\n",
        "- **Right dominance:** `d_crux_rca < d_crux_lcx` (koniec RCA bliżej crux).\n",
        "- **Left dominance:** `d_crux_lcx < d_crux_rca` (koniec LCx bliżej crux).\n",
        "- Jeśli brak któregoś z detekcji — fallback (np. confidence-weighted lub \"unknown\")."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from typing import Optional, Literal\n",
        "\n",
        "def bbox_center(xyxy: np.ndarray) -> np.ndarray:\n",
        "    \"\"\"xyxy [x1,y1,x2,y2] -> [cx, cy].\"\"\"\n",
        "    return np.array([(xyxy[0] + xyxy[2]) / 2, (xyxy[1] + xyxy[3]) / 2])\n",
        "\n",
        "def landmark_detections_to_centers(detections) -> dict:\n",
        "    \"\"\"Ze supervision Detections wyciąga centra bboxów per class_id (1–5).\"\"\"\n",
        "    centers = {}\n",
        "    if hasattr(detections, \"xyxy\") and detections.xyxy is not None and len(detections.xyxy):\n",
        "        for i, cid in enumerate(detections.class_id):\n",
        "            cid_int = int(cid) if hasattr(cid, \"__int__\") else cid\n",
        "            centers[cid_int] = bbox_center(detections.xyxy[i])\n",
        "    return centers\n",
        "\n",
        "def dominance_from_landmarks(\n",
        "    centers: dict,\n",
        "    crux_id: int = LANDMARK_ID_CRUX,\n",
        "    distal_rca_id: int = LANDMARK_ID_DISTAL_RCA,\n",
        "    distal_lcx_id: int = LANDMARK_ID_DISTAL_LCX,\n",
        ") -> Literal[\"right\", \"left\", \"unknown\"]:\n",
        "    \"\"\"\n",
        "    Right: dystalny RCA bliżej Crux. Left: dystalny LCx bliżej Crux.\n",
        "    \"\"\"\n",
        "    if crux_id not in centers:\n",
        "        return \"unknown\"\n",
        "    crux = np.array(centers[crux_id])\n",
        "    d_rca = np.inf\n",
        "    d_lcx = np.inf\n",
        "    if distal_rca_id in centers:\n",
        "        d_rca = np.linalg.norm(crux - np.array(centers[distal_rca_id]))\n",
        "    if distal_lcx_id in centers:\n",
        "        d_lcx = np.linalg.norm(crux - np.array(centers[distal_lcx_id]))\n",
        "    if d_rca == np.inf and d_lcx == np.inf:\n",
        "        return \"unknown\"\n",
        "    if d_rca < d_lcx:\n",
        "        return \"right\"\n",
        "    if d_lcx < d_rca:\n",
        "        return \"left\"\n",
        "    return \"unknown\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Przykład użycia na wyjściu modelu (detections = sv.Detections z model_landmark.predict(...))\n",
        "# centers = landmark_detections_to_centers(detections)\n",
        "# dom = dominance_from_landmarks(centers)\n",
        "# print(\"Dominance:\", dom)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. Pełna inferencja: obraz → detekcje landmarków → dominacja\n",
        "\n",
        "Dla każdej detekcji per klasa można brać **najwyższy confidence** (jedna reprezentacja punktu na klasę). Integracja z pipeline: zamiast `side_classifier` można użyć wyjścia tego modelu + `dominance_from_landmarks`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def landmarks_to_centers_best_per_class(detections, class_ids: list = None):\n",
        "    \"\"\"\n",
        "    Dla każdej klasy landmarku (1–5) wybiera detekcję z najwyższym confidence,\n",
        "    zwraca dict class_id -> center [cx, cy].\n",
        "    \"\"\"\n",
        "    if class_ids is None:\n",
        "        class_ids = list(range(1, 6))\n",
        "    centers = {}\n",
        "    if detections.xyxy is None or len(detections.xyxy) == 0:\n",
        "        return centers\n",
        "    conf = getattr(detections, \"confidence\", None)\n",
        "    if conf is None:\n",
        "        conf = np.ones(len(detections.class_id))\n",
        "    for cid in class_ids:\n",
        "        idx = np.where(np.array(detections.class_id) == cid)[0]\n",
        "        if len(idx) == 0:\n",
        "            continue\n",
        "        best_i = idx[np.argmax(conf[idx])]\n",
        "        centers[int(cid)] = bbox_center(detections.xyxy[best_i])\n",
        "    return centers\n",
        "\n",
        "# Pełny flow:\n",
        "# detections = model_landmark.predict(image, threshold=0.3)\n",
        "# centers = landmarks_to_centers_best_per_class(detections)\n",
        "# dominance = dominance_from_landmarks(centers)\n",
        "# print(\"Dominance:\", dominance)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.0rc1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
